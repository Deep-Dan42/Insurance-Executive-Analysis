{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be87d85c-64fe-4e07-92da-c0c29e0216b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fakerNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading faker-37.0.0-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: tzdata in c:\\users\\danil\\anaconda3\\lib\\site-packages (from faker) (2023.3)\n",
      "Downloading faker-37.0.0-py3-none-any.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/1.9 MB 487.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.3/1.9 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.9/1.9 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 9.4 MB/s eta 0:00:00\n",
      "Installing collected packages: faker\n",
      "Successfully installed faker-37.0.0\n"
     ]
    }
   ],
   "source": [
    "pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "67b1ad16-41d8-4af1-ad28-8dbc5865bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "from random import choice, choices, randint, uniform\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "93e05300-c040-4fed-9a3f-e794c6ee6ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faker library\n",
    "fake = Faker()\n",
    "\n",
    "# European countries for location\n",
    "europe_countries = [\"Sweden\", \"Portugal\", \"Switzerland\", \"Italy\", \"Denmark\", \"Germany\", \"France\", \"Netherlands\", \"Norway\"]\n",
    "\n",
    "# Defining line_of_business and their corresponding range amounts\n",
    "line_of_business = {\n",
    "    \"Auto\": {\"premium\": (2000, 50000), \"claim\": (10000, 50000), \"expense\": (500, 5000)},\n",
    "    \"Engineering\": {\"premium\": (50000, 500000), \"claim\": (150000, 1500000), \"expense\": (5000, 35000)},\n",
    "    \"Residence\": {\"premium\": (2000, 100000), \"claim\": (10000, 200000), \"expense\": (1000, 10000)},\n",
    "    \"Liability\": {\"premium\": (50000, 500000), \"claim\": (150000, 1000000), \"expense\": (10000, 50000)},\n",
    "    \"Transportation\": {\"premium\": (15000, 250000), \"claim\": (50000, 350000), \"expense\": (5000, 35000)}\n",
    "}\n",
    "\n",
    "# Defining Line_of_Business probabilities across the year - presenting more realistic variations to dataset \n",
    "lob_probabilities_by_year = {\n",
    "    2020: {\"Auto\": 0.25, \"Residence\": 0.32, \"Transportation\": 0.17, \"Engineering\": 0.13, \"Liability\": 0.13},\n",
    "    2021: {\"Auto\": 0.32, \"Residence\": 0.28, \"Transportation\": 0.18, \"Engineering\": 0.12, \"Liability\": 0.10},\n",
    "    2022: {\"Auto\": 0.30, \"Residence\": 0.26, \"Transportation\": 0.20, \"Engineering\": 0.14, \"Liability\": 0.10},\n",
    "    2023: {\"Auto\": 0.35, \"Residence\": 0.30, \"Transportation\": 0.15, \"Engineering\": 0.10, \"Liability\": 0.10},\n",
    "    2024: {\"Auto\": 0.28, \"Residence\": 0.25, \"Transportation\": 0.22, \"Engineering\": 0.15, \"Liability\": 0.10}\n",
    "}\n",
    "\n",
    "# Channel Distribution\n",
    "sales_channel_distribution = {\n",
    "    2020: (50, 50),\n",
    "    2021: (40, 60),\n",
    "    2022: (35, 65),\n",
    "    2023: (55, 45),\n",
    "    2024: (70, 30)\n",
    "}\n",
    "\n",
    "used_policy_ids = set() #Keeping track of Policy_IDs to ensure uniqueness across all years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "df8ff56d-90eb-4ee4-afce-8b20f38f88dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Policy Dataset\n",
    "def generate_policy_data(n, year):\n",
    "    policies = []\n",
    "\n",
    "    start_date = datetime(year, 1, 1)\n",
    "    end_date = datetime(year, 12, 31)\n",
    "\n",
    "    for i in range(n):\n",
    "        policy_id = randint(100000, 999999)\n",
    "        while policy_id in used_policy_ids:\n",
    "            policy_id = randint(100000, 999999)\n",
    "        used_policy_ids.add(policy_id)\n",
    "\n",
    "        issue_date = fake.date_between(start_date=start_date, end_date=end_date)\n",
    "        effective_date = issue_date\n",
    "        end_of_effective_date = effective_date + timedelta(days=365)\n",
    "        reference_date = datetime(year, 12, 31)\n",
    "\n",
    "        sales_location = choice(europe_countries)\n",
    "\n",
    "        # Apply probability distribution for Line of Business selection\n",
    "        lob_keys = list(lob_probabilities_by_year[year].keys())\n",
    "        lob_weights = list(lob_probabilities_by_year[year].values())\n",
    "        line_of_business_type = choices(lob_keys, weights=lob_weights)[0]\n",
    "\n",
    "        digital_weight, non_digital_weight = sales_channel_distribution[year]\n",
    "        sales_channel = np.random.choice([\"Digital\", \"Non-Digital\"], p = [digital_weight/100, non_digital_weight/100])\n",
    "\n",
    "        premium_amount = round(uniform(*line_of_business[line_of_business_type][\"premium\"]), 2)\n",
    "\n",
    "        policies.append([\n",
    "            policy_id, issue_date, effective_date, end_of_effective_date, reference_date,\n",
    "            sales_location, line_of_business_type, sales_channel, premium_amount\n",
    "        ])\n",
    "\n",
    "    return policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e1a22c6e-1257-4de3-96ad-1a124feb7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing Claim Dataset\n",
    "def generate_claim_data(policies, year):\n",
    "    claims = []\n",
    "    claim_id_counter = 1\n",
    "\n",
    "    for policy in policies:\n",
    "        if np.random.rand() < np.random.uniform(0.3, 0.6): #Chance of claims\n",
    "            policy_id = policy[0] # Extract Policy ID\n",
    "            occurrence_date = policy[2] + timedelta(days=randint(30, 360))\n",
    "\n",
    "            # Set claims status probability by Line of Business\n",
    "            if policy[6] in [\"Engineering\", \"Liability\"]:\n",
    "                claim_status = np.random.choice([\"Settled\", \"Pending\"], p=[0.30, 0.70])\n",
    "            else:\n",
    "                claim_status = np.random.choice([\"Settled\", \"Pending\"], p=[0.40, 0.60])\n",
    "\n",
    "            # Set probability distribution for payment_date\n",
    "            if claim_status == \"Settled\":\n",
    "                if np.random.rand() < 0.80:\n",
    "                    payment_date = occurrence_date + timedelta(days=randint(30, 180))\n",
    "                else:\n",
    "                    payment_date = occurrence_date + timedelta(days=365)\n",
    "            else:\n",
    "                payment_date = None\n",
    "\n",
    "            # Set probability distribution for claim_amount\n",
    "            if np.random.rand() < 0.90:\n",
    "                claim_amount = round(uniform(line_of_business[policy[6]][\"claim\"][0] * 1.2, line_of_business[policy[6]][\"claim\"][1] * 0.8), 2)\n",
    "                expense_amount = round(uniform(line_of_business[policy[6]][\"expense\"][0] * 1.2, line_of_business[policy[6]][\"expense\"][1] * 0.8), 2)\n",
    "            else:\n",
    "                claim_amount = round(uniform(line_of_business[policy[6]][\"claim\"][1] * 0.8, line_of_business[policy[6]][\"claim\"][1]), 2)\n",
    "                expense_amount = round(uniform(line_of_business[policy[6]][\"expense\"][1] * 0.8, line_of_business[policy[6]][\"expense\"][1]), 2)\n",
    "\n",
    "            claim_id = f\"C{year}-{str(claim_id_counter).zfill(4)}\" #Format CLaim ID \n",
    "\n",
    "            claims.append([claim_id, policy_id, occurrence_date, claim_status, claim_amount, payment_date, expense_amount])\n",
    "            claim_id_counter += 1\n",
    "\n",
    "    return claims\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "007d7b01-32c7-4281-88a8-cba3bb54fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed datasets and saved Policy_Dataset_2020.csv and Claim_Dataset_2020.csv\n",
      "Processed datasets and saved Policy_Dataset_2021.csv and Claim_Dataset_2021.csv\n",
      "Processed datasets and saved Policy_Dataset_2022.csv and Claim_Dataset_2022.csv\n",
      "Processed datasets and saved Policy_Dataset_2023.csv and Claim_Dataset_2023.csv\n",
      "Processed datasets and saved Policy_Dataset_2024.csv and Claim_Dataset_2024.csv\n"
     ]
    }
   ],
   "source": [
    "# Processing functions for databases\n",
    "years = [2020, 2021, 2022, 2023, 2024]\n",
    "for year in years:\n",
    "    policy_data = generate_policy_data(20000, year)\n",
    "    claim_data = generate_claim_data(policy_data, year)\n",
    "\n",
    "# To dataframe\n",
    "    policy_df = pd.DataFrame(policy_data, columns=[\n",
    "    \"Policy_ID\", \"Issue_Date\", \"Effective_Date\", \"End_Of_Effective_Date\", \"Reference_Date\", \"Sales_Location\",\n",
    "    \"Line_Of_Business\", \"Sales_Channel\", \"Premium_Amount\"\n",
    "    ])\n",
    "\n",
    "    claim_df = pd.DataFrame(claim_data, columns=[\n",
    "    \"Claim_ID\", \"Policy_ID\", \"Occurrence_Date\", \"Claim_Status\", \"Claim_Amount\", \"Payment_Date\", \"Expense_Amount\"\n",
    "    ])\n",
    "\n",
    "    policy_filename = f\"Policy_Dataset_{year}.csv\"\n",
    "    claim_filename = f\"Claim_Dataset_{year}.csv\"\n",
    "\n",
    "# Exporting to csv\n",
    "    policy_df.to_csv(policy_filename, index=False)\n",
    "    claim_df.to_csv(claim_filename, index=False)\n",
    "\n",
    "    print(f\"Processed datasets and saved {policy_filename} and {claim_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53634bea-e56a-4c5b-a296-dda1f6dcfa5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
